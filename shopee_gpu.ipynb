{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"shopee_gpu.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOA6CktaVvOBaxiWlb1EDze"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DDY25bjjOpSE"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"1UIwGlQFOmTt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616169506411,"user_tz":-60,"elapsed":558,"user":{"displayName":"Gerald Kung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjauO0FieWrM2BTXARxNOrzIl9Y_nzs62cGSz5XzA=s64","userId":"04167396740025867182"}},"outputId":"a19811e5-ee9b-42aa-b85d-1304c5181ade"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Fri Mar 19 15:58:26 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   67C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vrx_9WH8PwfG"},"source":["# Install RAPIDS\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n","\n","import sys, os\n","\n","dist_package_index = sys.path.index('/usr/local/lib/python3.7/dist-packages')\n","sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.7/site-packages'] + sys.path[dist_package_index:]\n","sys.path\n","exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKn6PvkPCVM5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616169546614,"user_tz":-60,"elapsed":21285,"user":{"displayName":"Gerald Kung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjauO0FieWrM2BTXARxNOrzIl9Y_nzs62cGSz5XzA=s64","userId":"04167396740025867182"}},"outputId":"0715fcb1-a6b0-4cd3-e05c-9b4388cfdf31"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0PXMAAo4Ob9W"},"source":["## Download Kaggle Data"]},{"cell_type":"code","metadata":{"id":"6TRfrQpqQh4L"},"source":["!pip install -q kaggle\n","from google.colab import files\n","files.upload()\n","\n","!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle competitions download -c shopee-product-matching\n","!unzip -q shopee-product-matching.zip -d ./drive/MyDrive/data/shopee\n","!rm shopee-product-matching.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l3O88-z7O2f6"},"source":["## Import Packages"]},{"cell_type":"code","metadata":{"id":"9OdpNGzkP_zc","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"error","timestamp":1616169552086,"user_tz":-60,"elapsed":2107,"user":{"displayName":"Gerald Kung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjauO0FieWrM2BTXARxNOrzIl9Y_nzs62cGSz5XzA=s64","userId":"04167396740025867182"}},"outputId":"f1712049-b2c8-4a08-8e46-78857249f45e"},"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.applications import EfficientNetB3\n","from cuml.neighbors import NearestNeighbors\n","from cuml.feature_extraction.text import TfidfVectorizer\n","import gc\n","import pandas as pd\n","import numpy as np\n","import cudf, cuml, cupy"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1832490b7c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNetB3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cuml'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"lcFptIELQbTt"},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","SEED = 100\n","BATCH_SIZE =32\n","CHUNK_SIZE = 2048\n","IMAGE_HEIGHT = 224\n","IMAGE_WIDTH = 224\n","LIMIT = 2.0\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs:\", len(physical_devices))\n","\n","if physical_devices:\n","  tf.config.experimental.set_virtual_device_configuration(\n","      physical_devices[0],\n","      [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n","  print('TensorFlow usage is restricted to max %iGB GPU RAM'%LIMIT)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1CpxXtUgPD17"},"source":["# Process Data"]},{"cell_type":"code","metadata":{"id":"_z9VmKGTfxpx"},"source":["def preprocess_image(image):\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, [IMAGE_WIDTH, IMAGE_HEIGHT])\n","#     image /= 255  # normalize to [0,1] rangeI'm not a \n","    return image\n","\n","def load_and_preprocess_image(path):\n","    image = tf.io.read_file(path)\n","    return preprocess_image(image)\n","\n","def augmentation(ds):\n","    data_augmentation = tf.keras.Sequential([\n","        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(0.3),\n","        layers.experimental.preprocessing.RandomTranslation(\n","            height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n","        layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n","    ])\n","    \n","    # Batch all datasets\n","    ds = ds.batch(BATCH_SIZE)\n","\n","    # Use data augmentation only on the training set\n","    ds = ds.map(lambda x: data_augmentation(x))\n","\n","    # Prefecting on all datasets\n","    return ds.prefetch(1)\n","\n","def prepare_data(df, augment=False):\n","    # Load images\n","    path_ds = tf.data.Dataset.from_tensor_slices(df['image_paths'])\n","    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n","\n","    if augment:\n","        ds = augmentation(image_ds)\n","    else:\n","        ds = image_ds.batch(BATCH_SIZE).prefetch(1)\n","    \n","    return ds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ly3wRLopf2Tp"},"source":["load_dir = './drive/MyDrive/data/shopee'\n","\n","# Load and process images\n","df_train = pd.read_csv(load_dir + '/train.csv')\n","df_train['image_paths'] = load_dir + '/train_images/' + df_train['image'] \n","\n","# Duplicate train set for runtime testing \n","# df_train = pd.concat([df_train, df_train], ignore_index=True)\n","train_ds = prepare_data(df_train, augment=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJ-2RN2wg8EJ"},"source":["# Embeddings"]},{"cell_type":"code","metadata":{"id":"1pJoEvr6tWeg"},"source":["def find_similar_items(embeddings, threshold, fine_tune=False):\n","  \"\"\"\n","  Using Nearest Neighbors to figure out similar items\n","  \"\"\"\n","  knn = NearestNeighbors(n_neighbors=50)\n","  knn.fit(embeddings)\n","\n","  num_chunk = round(embeddings.shape[0] / CHUNK_SIZE)\n","  item_index = []\n","  for i in range(num_chunk+1):\n","      start_idx = i * CHUNK_SIZE                  \n","      end_idx = min((i + 1) * CHUNK_SIZE, embeddings.shape[0])\n","      if not fine_tune:\n","        print('Chunk', start_idx, 'to', end_idx) \n","\n","      dist, idx = knn.kneighbors(embeddings[start_idx:end_idx, :])\n","      counts = (dist < threshold).sum(axis=1)\n","      chunk_index = [idx[i, :counts[i]].tolist() for i in range(end_idx - start_idx)]\n","      item_index += chunk_index\n","\n","  del embeddings, dist, idx, counts, chunk_index, knn\n","  _ = gc.collect()\n","  return item_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbbSumnkgtrB"},"source":["# Image embedding\n","effnet = EfficientNetB3(weights='imagenet', include_top=False, pooling='avg', input_shape=None)\n","embeddings_image = effnet.predict(train_ds, verbose=1)\n","\n","del effnet\n","_ = gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DAnYUhgp1Yfp"},"source":["# Similiar images\n","image_index = find_similar_items(embeddings_image, 6.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MSGb3MjPiQOb"},"source":["# Text embedding\n","cudf_train = cudf.DataFrame(df_train)\n","sentences = cudf_train.title\n","vectorizer = TfidfVectorizer(binary=True, max_features=15000)\n","embeddings_text = vectorizer.fit_transform(sentences).toarray()\n","\n","del sentences, vectorizer\n","_ = gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a2LwjNUwk7p"},"source":["# Similar texts\n","text_index = find_similar_items(embeddings_text, 0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ps0OTSuvk0M"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"qcFH0yMYv12s"},"source":["def row_wise_f1_score(y_true, y_pred):\n","\n","    y_true = y_true.apply(lambda x: set(x))\n","    y_pred = y_pred.apply(lambda x: set(x.split()))\n","\n","    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n","    fp = y_pred.apply(lambda x: len(x)).values - tp\n","    fn = y_true.apply(lambda x: len(x)).values - tp\n","\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","    f1 = 2 * ((precision * recall) / (precision + recall))\n","    return f1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hy87YVViW8T"},"source":["# Ground truth\n","tmp = df_train.groupby('label_group').posting_id.agg('unique').to_dict()\n","df_train['target'] = df_train.label_group.map(tmp)\n","\n","df_train['matches'] = [\n","    ' '.join(\n","        set(df_train['posting_id'][text].tolist() +\n","            df_train['posting_id'][image].tolist()))\n","    for text, image in zip(text_index, image_index)\n","]\n","\n","df_train['f1'] = row_wise_f1_score(df_train['target'], df_train['matches'])\n","df_train['f1'].mean()"],"execution_count":null,"outputs":[]}]}